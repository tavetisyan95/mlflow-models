{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c5a2f9-6bc1-44d7-88bf-e93052de83b2",
   "metadata": {},
   "source": [
    "# Saving Models with MLflow Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605bb6cc-fa62-4e61-bfce-c0c4a96c16dc",
   "metadata": {},
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd0e75a-86fa-428b-bb67-bdb90551d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import mlflow\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from mlflow.models import infer_signature, ModelSignature\n",
    "from mlflow.types import Schema, ColSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34d970-fbb7-4eba-b11d-400c9d2f9590",
   "metadata": {},
   "source": [
    "## Fitting a scikit-learn estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb13da72-5d39-458f-bb61-b06e381ed401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tigra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "data = datasets.load_breast_cancer()\n",
    "    \n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, \n",
    "                                                    data.target,\n",
    "                                                    stratify=data.target)\n",
    "\n",
    "# Instantiating and fitting the model\n",
    "model = LogisticRegression(max_iter=1000)            \n",
    "model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd9651-e629-46de-b478-e0c421ed5d73",
   "metadata": {},
   "source": [
    "## Providing input signature and input examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b800a-4ae7-466d-9576-d982e173e3df",
   "metadata": {},
   "source": [
    "### Inferring the input signature automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36334b4-50fa-446c-9eda-a7d5c05f16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting train features into a DataFrame\n",
    "X_train_df = pd.DataFrame(data=X_train, columns=data.feature_names)\n",
    "\n",
    "# Inferring the input signature\n",
    "signature = infer_signature(model_input=X_train_df, \n",
    "                            model_output=model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a5aa21d-3a6b-43af-a8ab-534b01229129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      "  ['mean radius': double, 'mean texture': double, 'mean perimeter': double, 'mean area': double, 'mean smoothness': double, 'mean compactness': double, 'mean concavity': double, 'mean concave points': double, 'mean symmetry': double, 'mean fractal dimension': double, 'radius error': double, 'texture error': double, 'perimeter error': double, 'area error': double, 'smoothness error': double, 'compactness error': double, 'concavity error': double, 'concave points error': double, 'symmetry error': double, 'fractal dimension error': double, 'worst radius': double, 'worst texture': double, 'worst perimeter': double, 'worst area': double, 'worst smoothness': double, 'worst compactness': double, 'worst concavity': double, 'worst concave points': double, 'worst symmetry': double, 'worst fractal dimension': double]\n",
      "outputs: \n",
      "  [Tensor('int32', (-1,))]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the signature\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bcd055-0782-4215-b702-4761a1bc5bd4",
   "metadata": {},
   "source": [
    "### Specifying the input signature manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f136fc71-92b5-4497-9011-1ad3326d1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input schema for the Iris dataset\n",
    "input_schema = Schema(inputs=[\n",
    "    ColSpec(type=\"double\", name=\"sepal length (cm)\"),\n",
    "    ColSpec(type=\"double\", name=\"sepal width (cm)\"),\n",
    "    ColSpec(type=\"double\", name=\"petal length (cm)\"),\n",
    "    ColSpec(type=\"double\", name=\"petal width (cm)\"),\n",
    "])\n",
    "\n",
    "# Example input schema for the Iris dataset\n",
    "output_schema = Schema(inputs=[ColSpec(type=\"long\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c174db3-7c3b-4203-8f2e-c3ae153ae81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an input schema for the breast cancer dataset\n",
    "input_schema = Schema(inputs=[ColSpec(type=\"double\", name=feature_name) \n",
    "                              for feature_name in data.feature_names])\n",
    "\n",
    "# Creating an output schema for the breast cancer dataset\n",
    "output_schema = Schema(inputs=[ColSpec(\"long\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e2f00f-a4da-4aad-aead-ba196251b218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius': double, 'mean texture': double, 'mean perimeter': double, 'mean area': double, 'mean smoothness': double, 'mean compactness': double, 'mean concavity': double, 'mean concave points': double, 'mean symmetry': double, 'mean fractal dimension': double, 'radius error': double, 'texture error': double, 'perimeter error': double, 'area error': double, 'smoothness error': double, 'compactness error': double, 'concavity error': double, 'concave points error': double, 'symmetry error': double, 'fractal dimension error': double, 'worst radius': double, 'worst texture': double, 'worst perimeter': double, 'worst area': double, 'worst smoothness': double, 'worst compactness': double, 'worst concavity': double, 'worst concave points': double, 'worst symmetry': double, 'worst fractal dimension': double]\n",
      "\n",
      " [long]\n"
     ]
    }
   ],
   "source": [
    "# Viewing the input schema\n",
    "print(input_schema)\n",
    "\n",
    "# Viewing the output schema\n",
    "print(\"\\n\", output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64cd15c9-1577-4b2b-8c87-8f80d14e7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatubg a signature from our schemas\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58bd117-10d5-496a-a13d-8059e7c8a852",
   "metadata": {},
   "source": [
    "### Providing input examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e883124f-237c-4f8c-808d-36cad409fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an input example from our feature DataFrame\n",
    "input_example = X_train_df.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f62e60-78b0-432f-a5e0-599f9ec8b421",
   "metadata": {},
   "source": [
    "## Specifying conda and pip dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed9765c7-a8d0-4a96-8587-51df6331cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying a conda environment\n",
    "conda_env = {\n",
    "    \"channels\": [\"default\"],\n",
    "    \"dependencies\": [\"pip\"],\n",
    "    \"pip\": [\"mlflow\", \"cloudpickle==1.6.0\"],\n",
    "    \"name\": \"mlflow-env\"}\n",
    "\n",
    "# Specifying pip requirements\n",
    "pip_requirements = [\"mlflow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac2d1c-fa53-4ad9-a267-6f254d8b74b8",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58ad647-2947-4e43-b764-646765f26c6e",
   "metadata": {},
   "source": [
    "### Saving a model to a local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f07d555-be11-4458-a307-8fd771682eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model \n",
    "mlflow.sklearn.save_model(sk_model=model, \n",
    "                          path=\"model\", \n",
    "                          conda_env=conda_env, \n",
    "                          signature=signature,\n",
    "                          input_example=input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec4b2c-739e-4141-b866-9e903380c83a",
   "metadata": {},
   "source": [
    "### Logging the model as an artifact under an MLflow run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92dfc47e-513a-42c7-98c9-5f156ea16c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving the model as an artifact in a run\n",
    "with mlflow.start_run() as run:\n",
    "    # Obtaining the ID of this run\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Logging our model\n",
    "    mlflow.sklearn.log_model(sk_model=model, \n",
    "                             artifact_path=\"model\", \n",
    "                             conda_env=conda_env, \n",
    "                             signature=signature,\n",
    "                             input_example=input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d07963-7633-48fb-bcdf-3e511158e2fa",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Loading our saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d32f68-1134-4a2d-90ab-c1c9d90dc17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the model saved with log_model\n",
    "model_uri_logged = \"runs:/{run_id}/model\"\n",
    "\n",
    "# Path to the model saved with save_model\n",
    "model_uri_saved = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7db94285-b28d-46a4-b9d6-0e1fdae62bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our model as a Python function\n",
    "pyfunc_model = mlflow.pyfunc.load_model(model_uri=model_uri_saved)\n",
    "\n",
    "# Loading our model as a scikit-learn model\n",
    "sklearn_model = mlflow.sklearn.load_model(model_uri=model_uri_saved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba24114-267c-4f2e-b4ec-78ca0ea6bf69",
   "metadata": {},
   "source": [
    "## Doing inference with the loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "005f21b5-e432-4c28-b67a-64a1ed7c74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference with the scikit-learn model\n",
    "sklearn_predictions = sklearn_model.predict(X_test)\n",
    "\n",
    "# Creating a DataFrame from our test features\n",
    "X_test_df = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "\n",
    "# Inferece with the Python function\n",
    "pyfunc_predictions = pyfunc_model.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04213b14-8d30-40ab-b676-0a822c5c2b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1\n",
      " 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0\n",
      " 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0] \n",
      "\n",
      " True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inspecting our predictions\n",
    "print(sklearn_predictions, \n",
    "      \"\\n\\n\", \n",
    "      np.equal(pyfunc_predictions, sklearn_predictions).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d479f-4d7e-4317-ac7a-7d07dfb3ed1c",
   "metadata": {},
   "source": [
    "# Serving models with MLflow Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632c01a-ced0-42f1-93b0-d7ab9730c696",
   "metadata": {},
   "source": [
    "## Doing inference with a served model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d9360-29b3-4195-84cd-81f9dd4f87c0",
   "metadata": {},
   "source": [
    "### Programmatic inference with MLflow Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36f53363-8176-4323-bc17-6f30f13d87f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the requests library for handling HTTP requests\n",
    "import requests\n",
    "\n",
    "# Declaring our endpoint and payload\n",
    "url = \"http://127.0.0.1:5000/invocations\"\n",
    "\n",
    "# Defining our query function\n",
    "def query(url, payload, headers={\"Content-Type\": \"application/json\"}):\n",
    "    return requests.post(url=url, \n",
    "                         data=payload, \n",
    "                         headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1442ae71-85b8-4dd4-b10c-f8a24db6b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting our test DataFrame to JSON with different data orientations\n",
    "# Records\n",
    "payload = X_test_df.to_json(orient=\"records\")\n",
    "\n",
    "# Split\n",
    "payload = X_test_df.to_json(orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a528709-c890-4167-a8dc-b519c99f6088",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Sending a POST request and obtaining the results\n",
    "response = query(url=url, \n",
    "                 payload=payload)\n",
    "\n",
    "# Inspecting the response\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a60b4d8-25a2-41f5-9d56-ec5bc9379aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Sending a POST request and obtaining the results\n",
    "response = query(url=url, \n",
    "                 payload=X_test_df.to_csv(), \n",
    "                 headers={\"Content-Type\": \"text/csv\"})\n",
    "\n",
    "# Inspecting the response\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
